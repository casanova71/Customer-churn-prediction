{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c6a368-0284-4f94-80c8-88aadae3e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b549e1-0c87-4b9c-9583-df35e22658ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/telco_cleaned1.csv')\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "X = df.drop(columns=['Churn', 'customerID'])\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4036d8-4580-40e2-b2ad-b0e8cb28e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3db7937-5a32-4631-aca5-baccf401f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "('num', StandardScaler(), numerical_cols),\n",
    "('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db7f3cb-d8fc-451a-8d17-2d784c8286f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    clf = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_val)\n",
    "        scores.append(f1_score(y_val, preds))\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edaebed-0a42-4a74-8596-ef86df1778e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 13:02:45,932] A new study created in memory with name: no-name-f3e8e3ba-05b6-4abb-930e-f98e2a1e775a\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:48,728] Trial 0 finished with value: 0.5881117496786947 and parameters: {'n_estimators': 321, 'max_depth': 3, 'learning_rate': 0.023467013776153914, 'subsample': 0.9487614293096867, 'colsample_bytree': 0.6028846725340212, 'gamma': 1.7905632786050325, 'reg_alpha': 2.417198553373737, 'reg_lambda': 2.777631924746751}. Best is trial 0 with value: 0.5881117496786947.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:50,923] Trial 1 finished with value: 0.5975941218367435 and parameters: {'n_estimators': 328, 'max_depth': 3, 'learning_rate': 0.11768613196542035, 'subsample': 0.8391923204392685, 'colsample_bytree': 0.9077227436005, 'gamma': 1.5889111793206467, 'reg_alpha': 4.919979825802317, 'reg_lambda': 0.846461095782618}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:52,853] Trial 2 finished with value: 0.5853777668316152 and parameters: {'n_estimators': 328, 'max_depth': 3, 'learning_rate': 0.2880636584974432, 'subsample': 0.933217121546934, 'colsample_bytree': 0.9405319049414773, 'gamma': 2.0709729458098813, 'reg_alpha': 4.606189811968632, 'reg_lambda': 2.679251584377542}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:54,347] Trial 3 finished with value: 0.5707169807765837 and parameters: {'n_estimators': 124, 'max_depth': 7, 'learning_rate': 0.26538850759727023, 'subsample': 0.9370657681424159, 'colsample_bytree': 0.9479561442339173, 'gamma': 0.6142850272751782, 'reg_alpha': 0.4492785310880276, 'reg_lambda': 3.3546835026203947}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:55,985] Trial 4 finished with value: 0.5943428911590546 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.2211518672800648, 'subsample': 0.6132862893130843, 'colsample_bytree': 0.9502501906453882, 'gamma': 3.3899114330918643, 'reg_alpha': 3.733310342217035, 'reg_lambda': 0.06398730608697112}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:02:58,141] Trial 5 finished with value: 0.5953765328367631 and parameters: {'n_estimators': 414, 'max_depth': 5, 'learning_rate': 0.15134788484244718, 'subsample': 0.7147933523571133, 'colsample_bytree': 0.9636452127642884, 'gamma': 4.71284409066219, 'reg_alpha': 2.314784910946963, 'reg_lambda': 2.549699898841575}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:02:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:01,931] Trial 6 finished with value: 0.5682242850863874 and parameters: {'n_estimators': 321, 'max_depth': 5, 'learning_rate': 0.17572325499885216, 'subsample': 0.67733269178832, 'colsample_bytree': 0.7293264061668308, 'gamma': 0.020028175705418816, 'reg_alpha': 3.5830499531269044, 'reg_lambda': 1.0789455656378428}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:04,507] Trial 7 finished with value: 0.5960801200534597 and parameters: {'n_estimators': 465, 'max_depth': 9, 'learning_rate': 0.16194913067970418, 'subsample': 0.5011350400203662, 'colsample_bytree': 0.5166581244900182, 'gamma': 3.0749455706788096, 'reg_alpha': 3.856805826967586, 'reg_lambda': 2.2390051507447515}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:06,942] Trial 8 finished with value: 0.5705345406011366 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.21907012063080428, 'subsample': 0.6741379637937661, 'colsample_bytree': 0.9118217025641262, 'gamma': 1.4987409192591272, 'reg_alpha': 0.15178533251381687, 'reg_lambda': 4.615927692776632}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:09,787] Trial 9 finished with value: 0.5844062837232797 and parameters: {'n_estimators': 340, 'max_depth': 4, 'learning_rate': 0.07282460459509359, 'subsample': 0.7437318201667569, 'colsample_bytree': 0.8640020128918016, 'gamma': 0.8241752848951184, 'reg_alpha': 4.586869112867116, 'reg_lambda': 3.6698410839568236}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:11,339] Trial 10 finished with value: 0.583733990032677 and parameters: {'n_estimators': 159, 'max_depth': 7, 'learning_rate': 0.10090105112393383, 'subsample': 0.8385701429738657, 'colsample_bytree': 0.7931420123266074, 'gamma': 4.048183565161926, 'reg_alpha': 1.3945044293506037, 'reg_lambda': 1.2633292171759116}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:14,109] Trial 11 finished with value: 0.5921378689586562 and parameters: {'n_estimators': 495, 'max_depth': 10, 'learning_rate': 0.11895853495995612, 'subsample': 0.5107481109707643, 'colsample_bytree': 0.500285929247106, 'gamma': 3.011180590839626, 'reg_alpha': 4.935065411329717, 'reg_lambda': 1.4170721509608935}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:16,356] Trial 12 finished with value: 0.5893723128890953 and parameters: {'n_estimators': 430, 'max_depth': 9, 'learning_rate': 0.16351608915684437, 'subsample': 0.832048409278981, 'colsample_bytree': 0.6642870193614878, 'gamma': 2.901621247360784, 'reg_alpha': 3.536404019790648, 'reg_lambda': 0.21238750664960815}. Best is trial 1 with value: 0.5975941218367435.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:19,450] Trial 13 finished with value: 0.599967338116473 and parameters: {'n_estimators': 411, 'max_depth': 8, 'learning_rate': 0.041204558837962244, 'subsample': 0.522535525603057, 'colsample_bytree': 0.8069425909798303, 'gamma': 2.3708270906338473, 'reg_alpha': 4.078432002746564, 'reg_lambda': 1.8398485954841943}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:23,666] Trial 14 finished with value: 0.5889959525754757 and parameters: {'n_estimators': 395, 'max_depth': 8, 'learning_rate': 0.013015601449752369, 'subsample': 0.8426330895160907, 'colsample_bytree': 0.8246014433918688, 'gamma': 2.2535652517009286, 'reg_alpha': 3.062295156841866, 'reg_lambda': 1.8096944888725846}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:26,806] Trial 15 finished with value: 0.5916660455688749 and parameters: {'n_estimators': 391, 'max_depth': 6, 'learning_rate': 0.05674425566243413, 'subsample': 0.5667830799132519, 'colsample_bytree': 0.7437745305185879, 'gamma': 1.2698460586058415, 'reg_alpha': 4.2811610649544765, 'reg_lambda': 0.6853244937420526}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:29,161] Trial 16 finished with value: 0.5931429145267492 and parameters: {'n_estimators': 249, 'max_depth': 8, 'learning_rate': 0.0597222036698504, 'subsample': 0.7992043707126277, 'colsample_bytree': 0.8588631157503703, 'gamma': 2.3929568437532294, 'reg_alpha': 3.088877034655104, 'reg_lambda': 1.931360882505671}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:31,510] Trial 17 finished with value: 0.5959947116951307 and parameters: {'n_estimators': 358, 'max_depth': 4, 'learning_rate': 0.12370393248574611, 'subsample': 0.5926114341044331, 'colsample_bytree': 0.6856575287094735, 'gamma': 3.8138551385583073, 'reg_alpha': 4.980049998066274, 'reg_lambda': 0.7116709077573238}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:34,108] Trial 18 finished with value: 0.5845563653209231 and parameters: {'n_estimators': 281, 'max_depth': 8, 'learning_rate': 0.08477616688284859, 'subsample': 0.8822001227858857, 'colsample_bytree': 0.8827661409724415, 'gamma': 1.0567529010148569, 'reg_alpha': 1.6307537807620438, 'reg_lambda': 1.6669331417004363}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:37,532] Trial 19 finished with value: 0.58174842341523 and parameters: {'n_estimators': 201, 'max_depth': 10, 'learning_rate': 0.03981384731619278, 'subsample': 0.7851524935844647, 'colsample_bytree': 0.7895113019519955, 'gamma': 0.31030563447675785, 'reg_alpha': 4.102413431129195, 'reg_lambda': 0.748273138520805}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:40,058] Trial 20 finished with value: 0.5932731738839025 and parameters: {'n_estimators': 456, 'max_depth': 5, 'learning_rate': 0.11327468167936795, 'subsample': 0.9866146318248794, 'colsample_bytree': 0.9994470139359191, 'gamma': 1.8103490845690433, 'reg_alpha': 3.0518942879527584, 'reg_lambda': 2.139551282790059}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:42,856] Trial 21 finished with value: 0.5882118462037815 and parameters: {'n_estimators': 481, 'max_depth': 9, 'learning_rate': 0.19764875208027366, 'subsample': 0.5304105675647883, 'colsample_bytree': 0.5082094885087696, 'gamma': 2.7787800249159895, 'reg_alpha': 3.880806867425442, 'reg_lambda': 3.2984346521481953}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:45,344] Trial 22 finished with value: 0.5942456773903307 and parameters: {'n_estimators': 445, 'max_depth': 8, 'learning_rate': 0.14107038282031248, 'subsample': 0.5048491125649296, 'colsample_bytree': 0.5654278307508764, 'gamma': 3.4677239808164098, 'reg_alpha': 4.320878021744513, 'reg_lambda': 2.1298172151719292}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:47,673] Trial 23 finished with value: 0.5938426779366701 and parameters: {'n_estimators': 377, 'max_depth': 7, 'learning_rate': 0.18114092479860291, 'subsample': 0.6323760873494753, 'colsample_bytree': 0.8077004680149321, 'gamma': 2.618974005779266, 'reg_alpha': 4.506069638500259, 'reg_lambda': 1.0865243681961174}. Best is trial 13 with value: 0.599967338116473.\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 13:03:51,292] Trial 24 finished with value: 0.5948702906203824 and parameters: {'n_estimators': 464, 'max_depth': 9, 'learning_rate': 0.09117095254954809, 'subsample': 0.5574298978517427, 'colsample_bytree': 0.6909741216916176, 'gamma': 1.6504751298515643, 'reg_alpha': 3.9778785441518076, 'reg_lambda': 2.381878727966313}. Best is trial 13 with value: 0.599967338116473.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec2972b-2c8a-4354-900e-d75e437c8e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;,\n",
       "                                                   &#x27;MonthlyCharges&#x27;,\n",
       "                                                   &#x27;TotalCharges&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;Partner&#x27;,\n",
       "                                                   &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;,\n",
       "                                                   &#x27;MultipleLines&#x27;,\n",
       "                                                   &#x27;InternetService&#x27;,\n",
       "                                                   &#x27;OnlineSecurity&#x27;,\n",
       "                                                   &#x27;OnlineBackup&#x27;,\n",
       "                                                   &#x27;DeviceProtection&#x27;,\n",
       "                                                   &#x27;TechSupport&#x27;, &#x27;Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=411,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;,\n",
       "                                                   &#x27;MonthlyCharges&#x27;,\n",
       "                                                   &#x27;TotalCharges&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;Partner&#x27;,\n",
       "                                                   &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;,\n",
       "                                                   &#x27;MultipleLines&#x27;,\n",
       "                                                   &#x27;InternetService&#x27;,\n",
       "                                                   &#x27;OnlineSecurity&#x27;,\n",
       "                                                   &#x27;OnlineBackup&#x27;,\n",
       "                                                   &#x27;DeviceProtection&#x27;,\n",
       "                                                   &#x27;TechSupport&#x27;, &#x27;Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=411,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;, &#x27;MonthlyCharges&#x27;,\n",
       "                                  &#x27;TotalCharges&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;gender&#x27;, &#x27;Partner&#x27;, &#x27;Dependents&#x27;,\n",
       "                                  &#x27;PhoneService&#x27;, &#x27;MultipleLines&#x27;,\n",
       "                                  &#x27;InternetService&#x27;, &#x27;OnlineSecurity&#x27;,\n",
       "                                  &#x27;OnlineBackup&#x27;, &#x27;DeviceProtection&#x27;,\n",
       "                                  &#x27;TechSupport&#x27;, &#x27;StreamingTV&#x27;,\n",
       "                                  &#x27;StreamingMovies&#x27;, &#x27;Contract&#x27;,\n",
       "                                  &#x27;PaperlessBilling&#x27;, &#x27;PaymentMethod&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;, &#x27;MonthlyCharges&#x27;, &#x27;TotalCharges&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;gender&#x27;, &#x27;Partner&#x27;, &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;, &#x27;MultipleLines&#x27;, &#x27;InternetService&#x27;, &#x27;OnlineSecurity&#x27;, &#x27;OnlineBackup&#x27;, &#x27;DeviceProtection&#x27;, &#x27;TechSupport&#x27;, &#x27;StreamingTV&#x27;, &#x27;StreamingMovies&#x27;, &#x27;Contract&#x27;, &#x27;PaperlessBilling&#x27;, &#x27;PaymentMethod&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8069425909798303, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=2.3708270906338473, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.041204558837962244,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=411, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['SeniorCitizen', 'tenure',\n",
       "                                                   'MonthlyCharges',\n",
       "                                                   'TotalCharges']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['gender', 'Partner',\n",
       "                                                   'Dependents', 'PhoneService',\n",
       "                                                   'MultipleLines',\n",
       "                                                   'InternetService',\n",
       "                                                   'OnlineSecurity',\n",
       "                                                   'OnlineBackup',\n",
       "                                                   'DeviceProtection',\n",
       "                                                   'TechSupport', 'Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=411,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params['use_label_encoder'] = False\n",
    "best_params['eval_metric'] = 'logloss'\n",
    "best_params['random_state'] = 42\n",
    "\n",
    "final_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',XGBClassifier(**best_params))\n",
    "])\n",
    "final_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91056e5-7532-462e-a0f8-e172fe1266ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4707  467]\n",
      " [ 808 1061]]\n",
      "\n",
      "Classification Rpeort\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      5174\n",
      "           1       0.69      0.57      0.62      1869\n",
      "\n",
      "    accuracy                           0.82      7043\n",
      "   macro avg       0.77      0.74      0.75      7043\n",
      "weighted avg       0.81      0.82      0.81      7043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_clf.predict(X)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Rpeort\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c8899c-f096-403d-b050-b666351d3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:03:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;,\n",
       "                                                   &#x27;MonthlyCharges&#x27;,\n",
       "                                                   &#x27;TotalCharges&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;Partner&#x27;,\n",
       "                                                   &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;,\n",
       "                                                   &#x27;MultipleLines&#x27;,\n",
       "                                                   &#x27;InternetService&#x27;,\n",
       "                                                   &#x27;OnlineSecurity&#x27;,\n",
       "                                                   &#x27;OnlineBackup&#x27;,\n",
       "                                                   &#x27;DeviceProtection&#x27;,\n",
       "                                                   &#x27;TechSupport&#x27;, &#x27;Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;,\n",
       "                                                   &#x27;MonthlyCharges&#x27;,\n",
       "                                                   &#x27;TotalCharges&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;Partner&#x27;,\n",
       "                                                   &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;,\n",
       "                                                   &#x27;MultipleLines&#x27;,\n",
       "                                                   &#x27;InternetService&#x27;,\n",
       "                                                   &#x27;OnlineSecurity&#x27;,\n",
       "                                                   &#x27;OnlineBackup&#x27;,\n",
       "                                                   &#x27;DeviceProtection&#x27;,\n",
       "                                                   &#x27;TechSupport&#x27;, &#x27;Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;, &#x27;MonthlyCharges&#x27;,\n",
       "                                  &#x27;TotalCharges&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;gender&#x27;, &#x27;Partner&#x27;, &#x27;Dependents&#x27;,\n",
       "                                  &#x27;PhoneService&#x27;, &#x27;MultipleLines&#x27;,\n",
       "                                  &#x27;InternetService&#x27;, &#x27;OnlineSecurity&#x27;,\n",
       "                                  &#x27;OnlineBackup&#x27;, &#x27;DeviceProtection&#x27;,\n",
       "                                  &#x27;TechSupport&#x27;, &#x27;StreamingTV&#x27;,\n",
       "                                  &#x27;StreamingMovies&#x27;, &#x27;Contract&#x27;,\n",
       "                                  &#x27;PaperlessBilling&#x27;, &#x27;PaymentMethod&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;SeniorCitizen&#x27;, &#x27;tenure&#x27;, &#x27;MonthlyCharges&#x27;, &#x27;TotalCharges&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;gender&#x27;, &#x27;Partner&#x27;, &#x27;Dependents&#x27;, &#x27;PhoneService&#x27;, &#x27;MultipleLines&#x27;, &#x27;InternetService&#x27;, &#x27;OnlineSecurity&#x27;, &#x27;OnlineBackup&#x27;, &#x27;DeviceProtection&#x27;, &#x27;TechSupport&#x27;, &#x27;StreamingTV&#x27;, &#x27;StreamingMovies&#x27;, &#x27;Contract&#x27;, &#x27;PaperlessBilling&#x27;, &#x27;PaymentMethod&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8069425909798303, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=2.3708270906338473, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.041204558837962244,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['SeniorCitizen', 'tenure',\n",
       "                                                   'MonthlyCharges',\n",
       "                                                   'TotalCharges']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['gender', 'Partner',\n",
       "                                                   'Dependents', 'PhoneService',\n",
       "                                                   'MultipleLines',\n",
       "                                                   'InternetService',\n",
       "                                                   'OnlineSecurity',\n",
       "                                                   'OnlineBackup',\n",
       "                                                   'DeviceProtection',\n",
       "                                                   'TechSupport', 'Streamin...\n",
       "                               gamma=2.3708270906338473, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.041204558837962244, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "best_params.update({\n",
    "    \"n_estimators\": 300,\n",
    "    \"use_label_encoder\": False,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"random_state\": 42\n",
    "})\n",
    "\n",
    "final_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", XGBClassifier(**best_params))\n",
    "])\n",
    "\n",
    "final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e0ae5c-81db-4dfb-9b4a-5a3fd8e109a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[4702  472]\n",
      " [ 808 1061]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      5174\n",
      "           1       0.69      0.57      0.62      1869\n",
      "\n",
      "    accuracy                           0.82      7043\n",
      "   macro avg       0.77      0.74      0.75      7043\n",
      "weighted avg       0.81      0.82      0.81      7043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = final_model.predict(X)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c15fbb4-a237-4da0-8d9f-411b0bb62e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved as churn_xgb_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(final_model, \"churn_xgb_pipeline.pkl\")\n",
    "print(\" Model saved as churn_xgb_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624583a-36e1-4a09-8ed3-344c3d84eade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
